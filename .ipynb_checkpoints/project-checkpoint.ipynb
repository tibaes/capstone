{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Phases\n",
    "\n",
    "1. Split dataset into train and test.\n",
    "2. Convert dataset notes into one-hot-encoded classification labels.\n",
    "3. Convert fingerprint images into 4D Tensors in the form _(nb_samples, 512, 512, 1)_.\n",
    "4. Model and compile the CNN architecture.\n",
    "5. Train the model with multiple epochs, using training and validation sets.\n",
    "6. Load the model with the best validation loss.\n",
    "7. Compute the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['path'], df['target'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Convert dataset notes into one-hot-encoded classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = { 'A': 1, 'T': 2, 'R': 3, 'W': 4, 'L': 0 }\n",
    "num_classes = len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = [ label[c] for c in y_train ]\n",
    "y_test = [ label[c] for c in y_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Phase 3: Convert fingerprint images into 4D Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorfy(img_path):\n",
    "    img = image.load_img(img_path, grayscale=True, target_size=(512, 512))\n",
    "    x = image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorfyList(img_path_list):\n",
    "    list_of_tensors = [tensorfy(img_path) for img_path in img_path_list]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = tensorfyList(X_train)\n",
    "X_test = tensorfyList(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Phase 4: Model and compile the CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', input_shape=(512, 512, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 512, 512, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 256, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 30,301\n",
      "Trainable params: 30,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Train the model with multiple epochs, using training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='best_model.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/20\n",
      "2208/2240 [============================>.] - ETA: 1s - loss: 2.5676 - acc: 0.2111Epoch 00000: val_loss improved from inf to 1.60043, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 93s - loss: 2.5536 - acc: 0.2107 - val_loss: 1.6004 - val_acc: 0.2000\n",
      "Epoch 2/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.6039 - acc: 0.2622Epoch 00001: val_loss improved from 1.60043 to 1.57500, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 15s - loss: 1.6033 - acc: 0.2629 - val_loss: 1.5750 - val_acc: 0.3339\n",
      "Epoch 3/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.5817 - acc: 0.2717Epoch 00002: val_loss improved from 1.57500 to 1.56702, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.5813 - acc: 0.2719 - val_loss: 1.5670 - val_acc: 0.3250\n",
      "Epoch 4/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.5444 - acc: 0.3039Epoch 00003: val_loss improved from 1.56702 to 1.47594, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.5446 - acc: 0.3067 - val_loss: 1.4759 - val_acc: 0.3804\n",
      "Epoch 5/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.5101 - acc: 0.3342Epoch 00004: val_loss did not improve\n",
      "2240/2240 [==============================] - 15s - loss: 1.5101 - acc: 0.3326 - val_loss: 1.4927 - val_acc: 0.3000\n",
      "Epoch 6/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.4622 - acc: 0.3723Epoch 00005: val_loss improved from 1.47594 to 1.37402, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.4649 - acc: 0.3710 - val_loss: 1.3740 - val_acc: 0.3964\n",
      "Epoch 7/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.3955 - acc: 0.3913Epoch 00006: val_loss did not improve\n",
      "2240/2240 [==============================] - 16s - loss: 1.3986 - acc: 0.3879 - val_loss: 1.4289 - val_acc: 0.4054\n",
      "Epoch 8/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.3568 - acc: 0.4253Epoch 00007: val_loss improved from 1.37402 to 1.30532, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 15s - loss: 1.3554 - acc: 0.4268 - val_loss: 1.3053 - val_acc: 0.4232\n",
      "Epoch 9/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.3296 - acc: 0.4461Epoch 00008: val_loss did not improve\n",
      "2240/2240 [==============================] - 16s - loss: 1.3277 - acc: 0.4473 - val_loss: 1.3095 - val_acc: 0.4571\n",
      "Epoch 10/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.2969 - acc: 0.4511Epoch 00009: val_loss improved from 1.30532 to 1.25865, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.2976 - acc: 0.4496 - val_loss: 1.2586 - val_acc: 0.4786\n",
      "Epoch 11/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.2552 - acc: 0.4783Epoch 00010: val_loss did not improve\n",
      "2240/2240 [==============================] - 16s - loss: 1.2597 - acc: 0.4759 - val_loss: 1.3586 - val_acc: 0.4089\n",
      "Epoch 12/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.2367 - acc: 0.4742Epoch 00011: val_loss improved from 1.25865 to 1.24112, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.2367 - acc: 0.4754 - val_loss: 1.2411 - val_acc: 0.4589\n",
      "Epoch 13/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.2098 - acc: 0.4864Epoch 00012: val_loss improved from 1.24112 to 1.17936, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.2073 - acc: 0.4875 - val_loss: 1.1794 - val_acc: 0.5214\n",
      "Epoch 14/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.1824 - acc: 0.5072Epoch 00013: val_loss improved from 1.17936 to 1.11881, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.1820 - acc: 0.5080 - val_loss: 1.1188 - val_acc: 0.5643\n",
      "Epoch 15/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.1595 - acc: 0.5204Epoch 00014: val_loss did not improve\n",
      "2240/2240 [==============================] - 16s - loss: 1.1620 - acc: 0.5183 - val_loss: 1.2067 - val_acc: 0.4768\n",
      "Epoch 16/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.1347 - acc: 0.5358Epoch 00015: val_loss did not improve\n",
      "2240/2240 [==============================] - 16s - loss: 1.1333 - acc: 0.5357 - val_loss: 1.3728 - val_acc: 0.3982\n",
      "Epoch 17/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.1442 - acc: 0.5195Epoch 00016: val_loss did not improve\n",
      "2240/2240 [==============================] - 16s - loss: 1.1446 - acc: 0.5192 - val_loss: 1.1302 - val_acc: 0.5196\n",
      "Epoch 18/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.1151 - acc: 0.5426Epoch 00017: val_loss improved from 1.11881 to 1.04820, saving model to best_model.hdf5\n",
      "2240/2240 [==============================] - 16s - loss: 1.1171 - acc: 0.5406 - val_loss: 1.0482 - val_acc: 0.5875\n",
      "Epoch 19/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.0936 - acc: 0.5476Epoch 00018: val_loss did not improve\n",
      "2240/2240 [==============================] - 20s - loss: 1.0974 - acc: 0.5469 - val_loss: 1.3121 - val_acc: 0.4446\n",
      "Epoch 20/20\n",
      "2208/2240 [============================>.] - ETA: 0s - loss: 1.0845 - acc: 0.5548Epoch 00019: val_loss did not improve\n",
      "2240/2240 [==============================] - 31s - loss: 1.0828 - acc: 0.5576 - val_loss: 1.0713 - val_acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca98226c50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.2, epochs=20, verbose=1,\n",
    "          callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Load the model with the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7: Compute the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 54.0000%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 100 * np.sum(np.array(predictions) == np.argmax(y_test, axis=1)) / len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
